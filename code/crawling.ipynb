{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get yesterday\n",
    "today = datetime.date.today()\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "yesterday = str(yesterday)\n",
    "yesterday = yesterday.replace(\"-\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date\n",
    "dates = []\n",
    "target_date = datetime.datetime(2022,1,20) # 2022-01-20 00:00:00\n",
    "for i in range(0,9):\n",
    "    target = target_date + relativedelta(days=i) # datetime.timedelta(days=i)\n",
    "    target = str(target.date()).replace(\"-\",\"\")\n",
    "    dates.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list\n",
    "fail = []\n",
    "\n",
    "def get_news() : \n",
    "    \n",
    "    # create datafame\n",
    "    df = pd.DataFrame(columns = ['제목','시간','언론사','본문'])\n",
    "    \n",
    "    # driver\n",
    "    path = 'C:\\selenium\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(path)\n",
    "    # driver.maximize_window() # 윈도우 창 최대화\n",
    "    # driver.minimize_window() # 윈도우 창 최소화\n",
    "    \n",
    "    \"\"\"\n",
    "    # get url\n",
    "    url = 'https://finance.naver.com/news/'\n",
    "    driver.get(url)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # click button(실시간 속보)\n",
    "    btn = driver.find_element_by_css_selector('div > ul > li.frst > a')\n",
    "    btn.click()\n",
    "    \n",
    "    # click button(날짜)\n",
    "    elems = driver.find_elements_by_css_selector('div.pagenavi_day > a')\n",
    "    for elem in elems:\n",
    "        if elem.text == '02월08일(화)' : \n",
    "            btn = elem\n",
    "    btn.click()\n",
    "    \"\"\"\n",
    "    \n",
    "    # set up page loop(페이지)\n",
    "    for date in dates:\n",
    "            print(\"====== DATE {0} CRAWLING START =====\".format(date))\n",
    "            # set up dates loop(날짜)\n",
    "            for page in tqdm(range(1,100)):\n",
    "                    try:\n",
    "                            # next_path = '//*[@id=\"contentarea_left\"]/table/tbody/tr/td/table/tbody/tr/td[{0}]/a'.format(page)\n",
    "                            # driver.find_element_by_xpath(next_path).click()\n",
    "                    \n",
    "                            # get url\n",
    "                            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={0}&page={1}'.format(date,page)\n",
    "                            driver.get(url)\n",
    "                            time.sleep(0.5)\n",
    "                        \n",
    "                            # click headline\n",
    "                            elems = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]')\n",
    "                            for i in range(len(elems)) :\n",
    "                                    btns = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]/a')\n",
    "                                    btns[i].click()\n",
    "                                    time.sleep(1)\n",
    "                            \n",
    "                                    tmp_dic ={}\n",
    "                            \n",
    "                                    # title\n",
    "                                    title_elem = driver.find_element_by_css_selector('div.article_info > h3')\n",
    "                                    title = title_elem.text\n",
    "                            #       print(title)\n",
    "                                    tmp_dic['제목'] = title\n",
    "                        \n",
    "                                    # time\n",
    "                                    time_elem = driver.find_element_by_css_selector('div.article_sponsor > span.article_date')\n",
    "                                    time_txt = time_elem.text\n",
    "                            #       print(time_txt)\n",
    "                                    tmp_dic['시간'] = time_txt\n",
    "                        \n",
    "                                    # press\n",
    "                                    press_elem = driver.find_element_by_css_selector('span.press > img')\n",
    "                                    press = press_elem.get_attribute('title')\n",
    "                            #       print(press)\n",
    "                                    tmp_dic['언론사'] = press\n",
    "                        \n",
    "                                    # content\n",
    "                                    content_elem = driver.find_element_by_css_selector('div.articleCont')\n",
    "                                    content = content_elem.text.replace('\\n', '')\n",
    "                            #       print(content)\n",
    "                                    tmp_dic['본문'] = content\n",
    "                            \n",
    "                                    df = df.append(tmp_dic, ignore_index = True)\n",
    "                            \n",
    "                                    time.sleep(1)\n",
    "                                    driver.back()\n",
    "                                    time.sleep(2)\n",
    "                        \n",
    "                    except:\n",
    "                            print(\"====== PAGE {0} CRAWLING FAIL =====\".format(page))\n",
    "                            fail.append([date,page])\n",
    "    \n",
    "    \n",
    "    for date, page in fail:\n",
    "            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={0}&page={1}'.format(date, page)\n",
    "            driver.get(url)\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # click headline\n",
    "            elems = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]')\n",
    "            for i in range(len(elems)) :\n",
    "                btns = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]/a')\n",
    "                btns[i].click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                tmp_dic = {}\n",
    "\n",
    "                # title\n",
    "                title_elem = driver.find_element_by_css_selector('div.article_info > h3')\n",
    "                title = title_elem.text\n",
    "                # print(title)\n",
    "                tmp_dic['제목'] = title\n",
    "\n",
    "                # time\n",
    "                time_elem = driver.find_element_by_css_selector('div.article_sponsor > span.article_date')\n",
    "                time_txt = time_elem.text\n",
    "                # print(time_txt)\n",
    "                tmp_dic['시간'] = time_txt\n",
    "\n",
    "                # press\n",
    "                press_elem = driver.find_element_by_css_selector('span.press > img')\n",
    "                press = press_elem.get_attribute('title')\n",
    "                # print(press)\n",
    "                tmp_dic['언론사'] = press\n",
    "\n",
    "                # content\n",
    "                content_elem = driver.find_element_by_css_selector('div.articleCont')\n",
    "                content = content_elem.text.replace('\\n', '')\n",
    "                # print(content)\n",
    "                tmp_dic['본문'] = content\n",
    "\n",
    "                df = df.append(tmp_dic, ignore_index=True)\n",
    "\n",
    "                time.sleep(1)\n",
    "                driver.back()\n",
    "                time.sleep(2)\n",
    "            \n",
    "    # close driver\n",
    "    driver.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220120 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:15:22<00:00, 45.69s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220121 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:09:15<00:00, 41.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220122 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [10:03<00:00,  6.10s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220123 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [17:17<00:00, 10.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220124 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:32:57<00:00, 56.34s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220125 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:26:10<00:00, 52.23s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220126 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:32:49<00:00, 56.26s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220127 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:51:39<00:00, 67.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DATE 20220128 CRAWLING START =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [1:17:18<00:00, 46.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "df = get_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>시간</th>\n",
       "      <th>언론사</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>칼 아이칸 보유 소식에…인터내셔널 플레이버스 &amp; 프레그런스 급등</td>\n",
       "      <td>2022-01-20 23:52</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>이 기사는 국내 최대 해외 투자정보 플랫폼 “한경 글로벌마켓”에 게재된 기사입니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>키방크, 월마트 투자의견 하향…\"중산층 지출 둔화 우려\"</td>\n",
       "      <td>2022-01-20 23:47</td>\n",
       "      <td>한국경제TV</td>\n",
       "      <td>미국 금융회사 키방크가 월마트에 대한 투자의견을 비중확대에서 중립으로 하향 조정했다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>고용 데이터 부진에도 3대 지수 상승출발···비욘드미트 급등 [뉴욕증시 나우]</td>\n",
       "      <td>2022-01-20 23:44</td>\n",
       "      <td>한국경제TV</td>\n",
       "      <td>여기는 미국 동부시간 20일 오전 9시 31분입니다. 매주 목요일은 미국의 경제 데...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>美 실업수당 청구 29만건…오미크론 여파 석달만에 최다</td>\n",
       "      <td>2022-01-20 23:34</td>\n",
       "      <td>한국경제TV</td>\n",
       "      <td>미국 내 실업수당 청구건수가 크게 늘었다.한동안 낮은 수준에 머무르던 실업수당 청구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>파미니티, ‘중기벤처부 장관상’ 수상…특허청 지식재산 경영인증도 획득</td>\n",
       "      <td>2022-01-20 23:11</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>[파이낸셜뉴스]파미니티는 수출증진과 활성화에 기여한 공로가 큼이 인정돼 중소벤처기업...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>[사진] 코스피 하루 새 95P 급락</td>\n",
       "      <td>2022-01-28 00:07</td>\n",
       "      <td>중앙일보</td>\n",
       "      <td>코스피 하루 새 95P 급락코스피가 27일 전날보다 94.75포인트(3.5%) 내린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>금감원 '사모펀드 불완전 판매' 하나은행에 업무 일부정지 3개월</td>\n",
       "      <td>2022-01-28 00:02</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>자본시장법 위반 판단해 과태료·관련 직원 징계 건의하나은행 본점[촬영 안 철 수](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>'따상' 실패한 LG에너지솔루션, 주가 전망은?</td>\n",
       "      <td>2022-01-28 00:01</td>\n",
       "      <td>더팩트</td>\n",
       "      <td>상장일 코스피 시총 2위 직행했지만 기대감 못 미쳐임인년 IPO(기업공개) 최대어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>외인·개인 '패닉셀'에 흔들리는 코스피…2600선도 내줄까</td>\n",
       "      <td>2022-01-28 00:01</td>\n",
       "      <td>더팩트</td>\n",
       "      <td>코스피, 3.50% 내린 2614.49…지난해 종가 대비 12.20%↓27일 코스피...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>[속보] 사모펀드 ‘불완전판매’ 하나은행, 업무 일부정지 ‘3개월’</td>\n",
       "      <td>2022-01-28 00:00</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>내부통제 마련 위반은 심의 안 해금융감독원/ 사진=뉴시스[파이낸셜뉴스] 금융감독원이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               제목                시간     언론사  \\\n",
       "0             칼 아이칸 보유 소식에…인터내셔널 플레이버스 & 프레그런스 급등  2022-01-20 23:52    한국경제   \n",
       "1                 키방크, 월마트 투자의견 하향…\"중산층 지출 둔화 우려\"  2022-01-20 23:47  한국경제TV   \n",
       "2     고용 데이터 부진에도 3대 지수 상승출발···비욘드미트 급등 [뉴욕증시 나우]  2022-01-20 23:44  한국경제TV   \n",
       "3                  美 실업수당 청구 29만건…오미크론 여파 석달만에 최다  2022-01-20 23:34  한국경제TV   \n",
       "4          파미니티, ‘중기벤처부 장관상’ 수상…특허청 지식재산 경영인증도 획득  2022-01-20 23:11  파이낸셜뉴스   \n",
       "...                                           ...               ...     ...   \n",
       "8200                         [사진] 코스피 하루 새 95P 급락  2022-01-28 00:07    중앙일보   \n",
       "8201          금감원 '사모펀드 불완전 판매' 하나은행에 업무 일부정지 3개월  2022-01-28 00:02    연합뉴스   \n",
       "8202                   '따상' 실패한 LG에너지솔루션, 주가 전망은?  2022-01-28 00:01     더팩트   \n",
       "8203             외인·개인 '패닉셀'에 흔들리는 코스피…2600선도 내줄까  2022-01-28 00:01     더팩트   \n",
       "8204        [속보] 사모펀드 ‘불완전판매’ 하나은행, 업무 일부정지 ‘3개월’  2022-01-28 00:00  파이낸셜뉴스   \n",
       "\n",
       "                                                     본문  \n",
       "0     이 기사는 국내 최대 해외 투자정보 플랫폼 “한경 글로벌마켓”에 게재된 기사입니다....  \n",
       "1     미국 금융회사 키방크가 월마트에 대한 투자의견을 비중확대에서 중립으로 하향 조정했다...  \n",
       "2     여기는 미국 동부시간 20일 오전 9시 31분입니다. 매주 목요일은 미국의 경제 데...  \n",
       "3     미국 내 실업수당 청구건수가 크게 늘었다.한동안 낮은 수준에 머무르던 실업수당 청구...  \n",
       "4     [파이낸셜뉴스]파미니티는 수출증진과 활성화에 기여한 공로가 큼이 인정돼 중소벤처기업...  \n",
       "...                                                 ...  \n",
       "8200  코스피 하루 새 95P 급락코스피가 27일 전날보다 94.75포인트(3.5%) 내린...  \n",
       "8201  자본시장법 위반 판단해 과태료·관련 직원 징계 건의하나은행 본점[촬영 안 철 수](...  \n",
       "8202  상장일 코스피 시총 2위 직행했지만 기대감 못 미쳐임인년 IPO(기업공개) 최대어 ...  \n",
       "8203  코스피, 3.50% 내린 2614.49…지난해 종가 대비 12.20%↓27일 코스피...  \n",
       "8204  내부통제 마련 위반은 심의 안 해금융감독원/ 사진=뉴시스[파이낸셜뉴스] 금융감독원이...  \n",
       "\n",
       "[8205 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save DataFrame\n",
    "df.to_csv(\"{0}-{1}_naver_finance_news.csv\".format(dates[0], dates[len(dates)-1]), encoding = 'utf-8-sig', index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver\n",
    "path = 'C:\\selenium\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "    \n",
    "# click page(페이지)\n",
    "for j in tqdm(range(59,62)):\n",
    "    # get url\n",
    "    url = 'https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={0}&page={1}'.format(yesterday,j)\n",
    "    driver.get(url)\n",
    "    time.sleep(0.5)\n",
    "                    \n",
    "    # click headline\n",
    "    elems = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]')\n",
    "    for i in range(len(elems)) :\n",
    "        btns = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]/a')\n",
    "        btns[i].click()\n",
    "        time.sleep(1)\n",
    "                            \n",
    "        tmp_dic ={}\n",
    "                            \n",
    "        # title\n",
    "        title_elem = driver.find_element_by_css_selector('div.article_info > h3')\n",
    "        title = title_elem.text\n",
    "#       print(title)\n",
    "        tmp_dic['제목'] = title\n",
    "                        \n",
    "        # time\n",
    "        time_elem = driver.find_element_by_css_selector('div.article_sponsor > span.article_date')\n",
    "        time_txt = time_elem.text\n",
    "#       print(time_txt)\n",
    "        tmp_dic['시간'] = time_txt\n",
    "                        \n",
    "        # press\n",
    "        press_elem = driver.find_element_by_css_selector('span.press > img')\n",
    "        press = press_elem.get_attribute('title')\n",
    "#       print(press)\n",
    "        tmp_dic['언론사'] = press\n",
    "                        \n",
    "        # content\n",
    "        content_elem = driver.find_element_by_css_selector('div.articleCont')\n",
    "        content = content_elem.text.replace('\\n', '')\n",
    "#       print(content)\n",
    "        tmp_dic['본문'] = content\n",
    "                            \n",
    "        df = df.append(tmp_dic, ignore_index = True)\n",
    "                            \n",
    "        time.sleep(1)\n",
    "        driver.back()\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news() : \n",
    "    \n",
    "    # driver\n",
    "    path = 'C:\\selenium\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(path)\n",
    "    # driver.maximize_window() # 윈도우 창 최대화\n",
    "    # driver.minimize_window() # 윈도우 창 최소화\n",
    "    \n",
    "    # create datafame\n",
    "    df = pd.DataFrame(columns = ['제목','시간','언론사','본문'])\n",
    "    \n",
    "    \"\"\"\n",
    "    # get url\n",
    "    url = 'https://finance.naver.com/news/'\n",
    "    driver.get(url)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # click button(실시간 속보)\n",
    "    btn = driver.find_element_by_css_selector('div > ul > li.frst > a')\n",
    "    btn.click()\n",
    "    \n",
    "    # click button(날짜)\n",
    "    elems = driver.find_elements_by_css_selector('div.pagenavi_day > a')\n",
    "    for elem in elems:\n",
    "        if elem.text == '02월08일(화)' : \n",
    "            btn = elem\n",
    "    btn.click()\n",
    "    \"\"\"\n",
    "    \n",
    "    # click page(페이지)\n",
    "    for j in tqdm(range(1,100)):\n",
    "            try:\n",
    "                    #next_path = '//*[@id=\"contentarea_left\"]/table/tbody/tr/td/table/tbody/tr/td[{0}]/a'.format(j)\n",
    "                    #driver.find_element_by_xpath(next_path).click()\n",
    "                    \n",
    "                    # get url\n",
    "                    url = 'https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258&date={0}&page={1}'.format(target_date1,j)\n",
    "                    driver.get(url)\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "                    # click headline\n",
    "                    elems = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]')\n",
    "                    for i in range(len(elems)) :\n",
    "                            btns = driver.find_elements_by_xpath('//dl/*[@class=\"articleSubject\"]/a')\n",
    "                            btns[i].click()\n",
    "                            time.sleep(1)\n",
    "                            \n",
    "                            tmp_dic ={}\n",
    "                            \n",
    "                            # title\n",
    "                            title_elem = driver.find_element_by_css_selector('div.article_info > h3')\n",
    "                            title = title_elem.text\n",
    "                    #       print(title)\n",
    "                            tmp_dic['제목'] = title\n",
    "                        \n",
    "                            # time\n",
    "                            time_elem = driver.find_element_by_css_selector('div.article_sponsor > span.article_date')\n",
    "                            time_txt = time_elem.text\n",
    "                    #       print(time_txt)\n",
    "                            tmp_dic['시간'] = time_txt\n",
    "                        \n",
    "                            # press\n",
    "                            press_elem = driver.find_element_by_css_selector('span.press > img')\n",
    "                            press = press_elem.get_attribute('title')\n",
    "                    #       print(press)\n",
    "                            tmp_dic['언론사'] = press\n",
    "                        \n",
    "                            # content\n",
    "                            content_elem = driver.find_element_by_css_selector('div.articleCont')\n",
    "                            content = content_elem.text.replace('\\n', '')\n",
    "                    #       print(content)\n",
    "                            tmp_dic['본문'] = content\n",
    "                            \n",
    "                            df = df.append(tmp_dic, ignore_index = True)\n",
    "                            \n",
    "                            time.sleep(1)\n",
    "                            driver.back()\n",
    "                            time.sleep(2)\n",
    "                            \n",
    "            except:\n",
    "                    print(\"======PAGE {0} CRAWLING FAIL=====\".format(j))\n",
    "\n",
    "    # close driver\n",
    "    driver.close()\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "402a3c6c354aab4e06709d0fc8b763e4288b1adf77f6fe8f78597203d73d70ec"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('stockessay')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
